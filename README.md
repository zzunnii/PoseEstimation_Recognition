# 인체 키포인트 기반 자세 인식 시스템

이 프로젝트는 키포인트 추출 기술과 고급 딥러닝 모델을 활용하여 인체 자세를 추정하고 인식하는 AI 기반 시스템을 구축하는 것을 목표로 합니다. 이 시스템은 20가지의 다양한 자세를 분류하고 정확한 피드백을 제공하며, 피트니스, 스포츠 분석, 재활 등 다양한 분야에 응용될 수 있습니다.

---

## 실행 영상

### 1. One Person Example
https://github.com/user-attachments/assets/a8db16a1-3c2f-4ef7-a000-7746bca93f27

### 2. Multiple People Example
https://github.com/user-attachments/assets/dc424715-e653-4e33-8b15-6983eaaa69bc

---



## 목차
1. [프로젝트 개요](#프로젝트-개요)
2. [시스템 구조](#시스템-구조)
3. [개발 환경](#개발-환경)
4. [주요 기능](#주요-기능)
5. [자세 분류 모델](#자세-분류-모델)
6. [데이터 전처리 및 증강](#데이터-전처리-및-증강)
7. [결과 및 성능](#결과-및-성능)
8. [사용 방법](#사용-방법)
9. [팀 구성 및 역할](#팀-구성-및-역할)

---

## 프로젝트 개요
### 주요 목표
1. **키포인트 추출**: Mediapipe와 YOLO를 활용하여 사람의 주요 관절 키포인트를 추출합니다.
2. **자세 분류**: MLP, GRU, Transformer 등의 모델을 사용하여 20가지 자세를 분류합니다.
3. **결과 시각화**: 정확도 및 그래픽 피드백을 제공합니다.

### 응용 분야
- **피트니스**: 운동 자세 교정 및 트레이닝 보조
- **스포츠 분석**: 선수들의 동작 분석 및 성능 향상
- **재활 의학**: 환자의 운동 치료 모니터링
- **게임 및 엔터테인먼트**: 모션 기반 게임 개발
- **산업 안전**: 작업자의 자세 모니터링 및 안전 관리

---

## 시스템 구조
1. **키포인트 추출**: Mediapipe와 YOLO를 사용하여 키포인트를 추출하고, 커스텀 알고리즘으로 통합합니다.
2. **정규화**: 어깨 너비와 골반 위치를 기준으로 키포인트를 표준화합니다.
3. **자세 분류**: 추출된 키포인트를 MLP, GRU, Transformer 모델에 입력합니다.
4. **시각화**: 결과를 정확도와 함께 그래픽으로 표시합니다.

---

## 개발 환경
- **IDE**: PyCharm, Google Colab
- **프로그래밍 언어**: Python (3.9/3.10)
- **하드웨어**:
  - **로컬**: AMD Ryzen 7900X, NVIDIA 4060 Ti (16GB), 32GB RAM
  - **클라우드**: NVIDIA A100 (40GB), 83.5GB RAM
- **라이브러리**:
  - Mediapipe (0.10.18)
  - YOLO (YOLOv8)
  - PyTorch (2.5.1)

---

## 주요 기능
- **키포인트 추출**:
  - Mediapipe를 사용하여 실시간으로 높은 정확도의 키포인트를 추출합니다.
  - YOLO를 통해 복잡한 환경에서도 사람의 위치를 정확하게 파악합니다.
- **데이터 증강**:
  - 좌우 반전, 노이즈 추가, 회전 등의 기법으로 데이터셋을 30만 개에서 300만 개 이상으로 확대했습니다.
- **자세 분류**:
  - "A 포즈", "T 포즈", "달리기", "기지개" 등 총 20가지의 자세를 분류합니다.
  - 사용된 모델: MLP, GRU, Transformer, CNN, Vision Transformer 등

---

## 자세 분류 모델
1. **MLP**: 정적인 자세 분류에 효과적입니다.
2. **GRU**: 연속적인 프레임 분석에 적합합니다.
3. **Transformer**: 복잡한 자세 간의 관계를 처리합니다.
4. **CNN**: 키포인트의 지역적 패턴을 추출합니다.
5. **Vision Transformer (ViT)**: 전역 및 지역 특징을 통합하여 분석합니다.

**메타 러너(Meta-Learner)**는 각 모델의 출력을 통합하여 정확도를 향상시킵니다.

---

## 데이터 전처리 및 증강
1. **데이터셋**: AI HUB의 한국인 신체 자세 데이터셋을 사용했습니다.
2. **전처리**:
   - 불필요한 필드를 제거하고 데이터를 정규화했습니다.
   - 어깨 너비와 골반 위치를 기준으로 스케일링했습니다.
3. **증강**:
   - 좌우 반전, 회전, 노이즈 추가 등의 기법을 적용했습니다.
   - 데이터 다양성을 높여 모델의 일반화 성능을 향상시켰습니다.

---

## 결과 및 성능
- **검증 데이터 정확도**: 99.57%
- **테스트 데이터 정확도**: 99.75%
- **실제 테스트 주요 통계**:
  - **총 자세 수**: 20가지 클래스
  - **테스트 이미지 수**: 71개
  - **정확히 예측한 수**: 60개 (전체 정확도: 84.51%)
- **주요 과제**:
  - 복잡하거나 유사한 자세에서의 오분류 문제
  - 모델 스태킹과 데이터 증강을 통해 개선

---

## 사용 방법
1. 리포지토리를 클론하고 환경을 설정합니다.
2. 다음 노트북을 순서대로 실행합니다:
   - `preprocess.ipynb`: 데이터 전처리 및 증강
   - `train.ipynb`: 모델 학습 및 검증
   - `pose_estimation_recognition.ipynb`: 자세 분류
   - `Analysis_Augmentation.ipynb`: 증강 기법 분석
3. 생성된 출력 파일에서 결과를 확인합니다.

---

## 팀 구성 및 역할
- **이성준 (20223181)**:
  - 키포인트 추출 및 자세 추정 알고리즘 개발
  - 주요 코딩 작업과 프로젝트 발표 준비
- **오승진 (20223179)**:
  - 키포인트 추출 개발에 기여
  - 코딩 및 기술 지원
- **이호성 (20223182)**:
  - 문서화 및 프로젝트 정리
  - 프로젝트 진행 상황 체계화 및 정보 공유 촉진

---

## 라이선스
이 프로젝트는 MIT 라이선스에 따라 오픈 소스로 제공됩니다.

---

이 README는 OpenAI의 ChatGPT에 의해 작성되었습니다.
